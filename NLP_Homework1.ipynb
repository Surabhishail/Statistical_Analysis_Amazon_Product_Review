{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************#\n",
    "#           HOMEWORK 1                      # \n",
    "# Corpus Statistics and Python Programming  #\n",
    "#  Submitted By: Surabhi Shail              #\n",
    "#  SUID        : 267102671                  #\n",
    "#  Email       : sshail@syr.edu             #\n",
    "#*******************************************#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk import FreqDist\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open(\"clothing_shoes_jewelry.txt\",\"rt\")\n",
    "rvtxt=open(\"ReviewText.txt\",\"w+\")\n",
    "contents = dataset.read()\n",
    "dataset.close()\n",
    "\n",
    "endword = re.compile('.*')\n",
    "mytext = re.findall(endword,contents)\n",
    "\n",
    "for line in mytext:\n",
    "    if \"reviewText\" in line:\n",
    "        review_split = line.split(\":\")\n",
    "        rvtxt.write(review_split[1]+\"\\n\")\n",
    "rvtxt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of clothing_shoes_jewelry txt file is =  139641164\n",
      "Length of ReviewTxt file is =  82523383\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of clothing_shoes_jewelry txt file is = \", len(contents))\n",
    "newfile=open(\"ReviewText.txt\",\"rt\")\n",
    "rvtext = newfile.read()\n",
    "\n",
    "print(\"Length of ReviewTxt file is = \", len(rvtext))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tutu',\n",
       " 'and',\n",
       " 'at',\n",
       " 'a',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " '.',\n",
       " 'It',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'look',\n",
       " 'cheap',\n",
       " 'at',\n",
       " 'all',\n",
       " '.',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'so',\n",
       " 'glad',\n",
       " 'I',\n",
       " 'looked',\n",
       " 'on',\n",
       " 'Amazon',\n",
       " 'and',\n",
       " 'found',\n",
       " 'such',\n",
       " 'an',\n",
       " 'affordable',\n",
       " 'tutu',\n",
       " 'that',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'made',\n",
       " 'poorly',\n",
       " '.',\n",
       " 'A++',\n",
       " 'I',\n",
       " 'bought',\n",
       " 'this',\n",
       " 'for',\n",
       " 'my',\n",
       " '4',\n",
       " 'yr',\n",
       " 'old',\n",
       " 'daughter']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('ReviewText.txt')\n",
    "reviewtext = f.read()\n",
    "reviewtokens = nltk.word_tokenize(reviewtext)\n",
    "reviewtokens[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17980606\n",
      "['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.', 'it', 'does', \"n't\", 'look', 'cheap', 'at', 'all', '.', 'i', \"'m\", 'so', 'glad', 'i', 'looked', 'on', 'amazon', 'and', 'found']\n"
     ]
    }
   ],
   "source": [
    "print(len(mywords))\n",
    "print(mywords[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.', 'it', 'does', \"n't\", 'look', 'cheap', 'at', 'all', '.', 'i', \"'m\", 'so', 'glad', 'i', 'looked', 'on', 'amazon', 'and', 'found', 'such', 'an', 'affordable', 'tutu', 'that', 'is', \"n't\", 'made', 'poorly', '.', 'a++', 'i', 'bought', 'this', 'for', 'my', '4', 'yr', 'old', 'daughter']\n"
     ]
    }
   ],
   "source": [
    "mywords = [w.lower() for w in reviewtokens]\n",
    "print(mywords[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tutu',\n",
       " 'and',\n",
       " 'at',\n",
       " 'a',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " 'it',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'look',\n",
       " 'cheap',\n",
       " 'at',\n",
       " 'all',\n",
       " 'i',\n",
       " \"'m\"]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "alphamywords = [w for w in mywords if not alpha_filter(w)]\n",
    "alphamywords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedwords = [w for w in alphamywords if not w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7717421"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoppedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'tutu',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " \"n't\",\n",
       " 'look',\n",
       " 'cheap',\n",
       " \"'m\",\n",
       " 'glad',\n",
       " 'looked',\n",
       " 'amazon',\n",
       " 'found',\n",
       " 'affordable',\n",
       " 'tutu',\n",
       " \"n't\",\n",
       " 'made',\n",
       " 'poorly',\n",
       " 'a++',\n",
       " 'bought']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoppedwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the list of stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend((\"/a\",\"wp\",\"/b\",\"'s\",\"b\",\"n't\",\"p\",\"/i\",\"dd\",\"/dd\",\"br\",\"q=\",\"/li\",\"rs\",\"li\",\"'m\",\"afd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now remove manually the added stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppedwords=[w for w in alphamywords if not w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7495725"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoppedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'tutu',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " 'look',\n",
       " 'cheap',\n",
       " 'glad',\n",
       " 'looked',\n",
       " 'amazon',\n",
       " 'found',\n",
       " 'affordable',\n",
       " 'tutu',\n",
       " 'made',\n",
       " 'poorly',\n",
       " 'a++',\n",
       " 'bought',\n",
       " 'yr',\n",
       " 'old',\n",
       " 'daughter']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoppedwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "outList = list(map(lemmatizer.lemmatize, stoppedwords))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7495725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'tutu',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " 'look',\n",
       " 'cheap',\n",
       " 'glad',\n",
       " 'looked',\n",
       " 'amazon',\n",
       " 'found',\n",
       " 'affordable',\n",
       " 'tutu',\n",
       " 'made',\n",
       " 'poorly',\n",
       " 'a++',\n",
       " 'bought',\n",
       " 'yr',\n",
       " 'old',\n",
       " 'daughter']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(outList))\n",
    "outList[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like 85565 0.004758738387349125\n",
      "size 81141 0.004512695512042253\n",
      "fit 77370 0.00430296954396309\n",
      "wear 76336 0.004245463139562705\n",
      "great 75950 0.004223995564999311\n",
      "would 63850 0.0035510482794628836\n",
      "love 58804 0.0032704125767507503\n",
      "good 57831 0.0032162987165171185\n",
      "well 55891 0.0031084046889187163\n",
      "comfortable 55699 0.003097726517115163\n",
      "one 52830 0.002938165710321443\n",
      "shoes 48102 0.0026752157296589447\n",
      "nice 44660 0.0024837872538889957\n",
      "really 43951 0.0024443558798852498\n",
      "bought 41603 0.002313770737204297\n",
      "little 40841 0.0022713917428589447\n",
      "look 40628 0.002259545646014378\n",
      "get 36477 0.002028685796240683\n",
      "price 33393 0.001857167661646109\n",
      "color 32430 0.0018036099561939125\n",
      "quality 32059 0.0017829766138026716\n",
      "pair 32038 0.001781808688761658\n",
      "ordered 31724 0.001764345428624597\n",
      "small 31286 0.001739985849197741\n",
      "perfect 30892 0.0017180733508091997\n",
      "time 30763 0.0017108989541286873\n",
      "shoe 29907 0.001663292104837846\n",
      "also 28115 0.0015636291680046824\n",
      "much 28098 0.0015626837048762427\n",
      "got 27909 0.00155217237950712\n",
      "buy 27895 0.001551393762813111\n",
      "made 26881 0.0014949996679755955\n",
      "looks 26425 0.0014696390099421565\n",
      "fits 25122 0.0013971720419211678\n",
      "bit 24464 0.0013605770573027404\n",
      "long 24301 0.001351511734365349\n",
      "even 24232 0.001347674266373447\n",
      "watch 23848 0.0013263179227663406\n",
      "feet 23793 0.0013232590714684477\n",
      "recommend 22233 0.0012364989255645778\n",
      "still 21910 0.0012185351261242252\n",
      "big 21789 0.001211805653268861\n",
      "work 21433 0.0011920065430497727\n",
      "back 21245 0.0011815508331587934\n",
      "wearing 20998 0.0011678138100573473\n",
      "cute 20891 0.0011618629538959922\n",
      "looking 20641 0.0011479590843601155\n",
      "pretty 20594 0.0011453451568873708\n",
      "'ve 20428 0.0011361129875155486\n",
      "could 20203 0.0011235995049332598\n"
     ]
    }
   ],
   "source": [
    "#Lets us find the 50 most common words\n",
    "fdist = nltk.FreqDist(stoppedwords)\n",
    "fdisttop= fdist.most_common(50)\n",
    "for i in fdisttop:\n",
    "    print (i[0],i[1],i[1]/len(mywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like 85565 0.001036857638276899\n",
      "size 81141 0.0009832485902813751\n",
      "fit 77370 0.0009375524510428759\n",
      "wear 76336 0.0009250226690294556\n",
      "great 75950 0.0009203452068851807\n",
      "would 63850 0.0007737200982174955\n",
      "love 58804 0.0007125737925697981\n",
      "good 57831 0.000700783194988504\n",
      "well 55891 0.0006772747064913711\n",
      "comfortable 55699 0.0006749480931968094\n",
      "one 52830 0.0006401821893317195\n",
      "shoes 48102 0.0005828893369531397\n",
      "nice 44660 0.0005411799465370924\n",
      "really 43951 0.0005325884422358206\n",
      "bought 41603 0.0005041359004877442\n",
      "little 40841 0.0004949021539749528\n",
      "look 40628 0.0004923210673512985\n",
      "get 36477 0.0004420201726339794\n",
      "price 33393 0.00040464894659008346\n",
      "color 32430 0.00039297952678454785\n",
      "quality 32059 0.00038848383130391054\n",
      "pair 32038 0.0003882293579748179\n",
      "ordered 31724 0.00038442437581600355\n",
      "small 31286 0.00037911678923778486\n",
      "perfect 30892 0.00037434238487290324\n",
      "time 30763 0.00037277919156561965\n",
      "shoe 29907 0.0003624063739606991\n",
      "also 28115 0.0003406913165447907\n",
      "much 28098 0.0003404853143260014\n",
      "got 27909 0.0003381950543641673\n",
      "buy 27895 0.0003380254054781055\n",
      "made 26881 0.00032573797901620197\n",
      "looks 26425 0.00032021227244161815\n",
      "fits 25122 0.00030442280826029636\n",
      "bit 24464 0.00029644931061539246\n",
      "long 24301 0.0002944741128705303\n",
      "even 24232 0.00029363798621779723\n",
      "watch 23848 0.000288984759628674\n",
      "feet 23793 0.0002883182818620027\n",
      "recommend 22233 0.00026941454884368956\n",
      "still 21910 0.00026550050668669266\n",
      "big 21789 0.00026403425560001583\n",
      "work 21433 0.00025972032678301613\n",
      "back 21245 0.0002574421845987579\n",
      "wearing 20998 0.000254449093537525\n",
      "cute 20891 0.00025315249133690994\n",
      "looking 20641 0.0002501230469429495\n",
      "pretty 20594 0.0002495535113968849\n",
      "'ve 20428 0.0002475419603192952\n",
      "could 20203 0.0002448154603647308\n"
     ]
    }
   ],
   "source": [
    "#List the top 50 words by frequency (normalized by the length of the document)  \n",
    "fdistribution=nltk.FreqDist(stoppedwords)\n",
    "fdistributiontop=fdistribution.most_common(50)\n",
    "for items in fdistributiontop:\n",
    "    print(items[0],items[1],items[1]/len(reviewtext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'great'),\n",
       " ('great', 'tutu'),\n",
       " ('tutu', 'and'),\n",
       " ('and', 'at'),\n",
       " ('at', 'a'),\n",
       " ('a', 'really'),\n",
       " ('really', 'great'),\n",
       " ('great', 'price'),\n",
       " ('price', '.'),\n",
       " ('.', 'it'),\n",
       " ('it', 'does'),\n",
       " ('does', \"n't\"),\n",
       " (\"n't\", 'look'),\n",
       " ('look', 'cheap'),\n",
       " ('cheap', 'at'),\n",
       " ('at', 'all'),\n",
       " ('all', '.'),\n",
       " ('.', 'i')]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewbigrams = list(nltk.bigrams(mywords))\n",
    "reviewbigrams[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 50 BIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(mywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('.', 'i'), 0.014682541845363833)\n",
      "(('.', 'the'), 0.005025692682437956)\n",
      "((',', 'but'), 0.0040761140086157275)\n",
      "(('.', 'it'), 0.0036366961158038834)\n",
      "((',', 'and'), 0.0035754634743678827)\n",
      "(('they', 'are'), 0.0033187980427356006)\n",
      "(('.', 'they'), 0.0031242551001896155)\n",
      "(('i', 'have'), 0.002846010863037653)\n",
      "(('in', 'the'), 0.0027320547483216085)\n",
      "((',', 'i'), 0.002694792377965459)\n",
      "(('it', 'is'), 0.0025473557454070237)\n",
      "(('it', \"'s\"), 0.002493019423260818)\n",
      "(('of', 'the'), 0.0024719967725225726)\n",
      "(('and', 'i'), 0.00235665027085294)\n",
      "(('.', 'this'), 0.002185076520780223)\n",
      "(('and', 'the'), 0.002146757456339347)\n",
      "(('&', '#'), 0.002035860192921195)\n",
      "(('is', 'a'), 0.001992424504491117)\n",
      "(('i', \"'m\"), 0.001960167527167883)\n",
      "(('i', 'am'), 0.0019560519817852636)\n",
      "(('#', '34'), 0.0018145105899100397)\n",
      "(('34', ';'), 0.0018145105899100397)\n",
      "(('!', 'i'), 0.0018002174120271585)\n",
      "(('a', 'little'), 0.0017937104010843684)\n",
      "(('do', \"n't\"), 0.001741598698063903)\n",
      "(('on', 'the'), 0.0017150701149894502)\n",
      "(('.', 'these'), 0.0017066165623116373)\n",
      "(('i', 'love'), 0.001695159773814075)\n",
      "(('i', 'was'), 0.0016787532077617406)\n",
      "(('!', '!'), 0.0016200788783203414)\n",
      "(('for', 'a'), 0.001600057306188679)\n",
      "(('this', 'is'), 0.0015751415719803881)\n",
      "(('for', 'the'), 0.001530537958509296)\n",
      "(('it', '.'), 0.0015082917672518935)\n",
      "(('and', 'it'), 0.0014939985893690124)\n",
      "(('i', 'bought'), 0.0014881589641639443)\n",
      "(('but', 'i'), 0.0014868241926885)\n",
      "(('i', 'would'), 0.0014298739430695494)\n",
      "(('for', 'my'), 0.0014273156310749481)\n",
      "(('and', 'they'), 0.0013976169657463158)\n",
      "(('so', 'i'), 0.0013436699519471145)\n",
      "(('these', 'are'), 0.001330211006236386)\n",
      "(('if', 'you'), 0.0013273746168510673)\n",
      "(('to', 'be'), 0.0013179756010448147)\n",
      "(('it', 'was'), 0.0012765420698279024)\n",
      "(('to', 'wear'), 0.001224764059676298)\n",
      "((',', 'the'), 0.0012141971188290317)\n",
      "((',', 'it'), 0.0011876129202764356)\n",
      "(('them', '.'), 0.0011826075272435201)\n",
      "((',', 'so'), 0.001180939062899215)\n"
     ]
    }
   ],
   "source": [
    "for bigramscore in score[:50]:\n",
    "    print (bigramscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('well', 'made'), 0.00048541189323652385)\n",
      "(('would', 'recommend'), 0.00033969934050053706)\n",
      "(('good', 'quality'), 0.0003354169486834871)\n",
      "(('highly', 'recommend'), 0.00028736517556749754)\n",
      "(('really', 'like'), 0.0002731276131627599)\n",
      "(('fit', 'perfectly'), 0.00024142679062096127)\n",
      "(('fit', 'well'), 0.00023720001428205478)\n",
      "(('look', 'like'), 0.00022463091622162233)\n",
      "(('looks', 'great'), 0.00022034852440457235)\n",
      "(('look', 'great'), 0.00020477619052439055)\n",
      "(('another', 'pair'), 0.00020388634287409445)\n",
      "(('year', 'old'), 0.00019165093768252304)\n",
      "(('looks', 'like'), 0.00018842523995019967)\n",
      "(('feel', 'like'), 0.00018397600169871916)\n",
      "(('great', 'price'), 0.00018236315283255748)\n",
      "(('fit', 'great'), 0.00017435452397989256)\n",
      "(('even', 'though'), 0.00017073951790056463)\n",
      "(('usually', 'wear'), 0.00016645712608351465)\n",
      "(('light', 'weight'), 0.00015928272940300234)\n",
      "(('normally', 'wear'), 0.00015266448750392506)\n",
      "(('fits', 'well'), 0.00015166340889734194)\n",
      "(('would', 'buy'), 0.00015166340889734194)\n",
      "(('one', 'size'), 0.0001513297160284809)\n",
      "(('long', 'time'), 0.00014982809811860625)\n",
      "(('every', 'day'), 0.00014148577639708028)\n",
      "(('look', 'good'), 0.00013942800370577053)\n",
      "(('size', 'larger'), 0.00013881623344619198)\n",
      "(('arch', 'support'), 0.00013876061796804846)\n",
      "(('little', 'bit'), 0.0001321423760689712)\n",
      "(('first', 'time'), 0.00013158622128753614)\n",
      "(('fits', 'perfectly'), 0.00013158622128753614)\n",
      "(('really', 'nice'), 0.00013075198911538353)\n",
      "(('half', 'size'), 0.00012730382947048614)\n",
      "(('much', 'better'), 0.0001252460567791764)\n",
      "(('great', 'quality'), 0.00012452305556331082)\n",
      "(('looks', 'good'), 0.00012202035904685304)\n",
      "(('high', 'quality'), 0.00012007381731183032)\n",
      "(('perfect', 'fit'), 0.00011968450896482577)\n",
      "(('different', 'colors'), 0.00011796042914237707)\n",
      "(('fits', 'great'), 0.00011618073384178487)\n",
      "(('long', 'enough'), 0.00011445665401933617)\n",
      "(('flip', 'flops'), 0.00011206518845916539)\n",
      "(('would', 'definitely'), 0.00011189834202473487)\n",
      "(('really', 'cute'), 0.00010439025247536151)\n",
      "(('definitely', 'recommend'), 0.00010361163578135242)\n",
      "(('second', 'pair'), 0.0001034447893469219)\n",
      "(('super', 'cute'), 0.00010155386309004268)\n",
      "(('good', 'price'), 0.00010016347613645502)\n",
      "(('fit', 'perfect'), 9.938485944244593e-05)\n",
      "(('size', 'smaller'), 9.810570344514528e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('well', 'made'), 0.00048541189323652385)\n",
      "(('would', 'recommend'), 0.00033969934050053706)\n",
      "(('good', 'quality'), 0.0003354169486834871)\n",
      "(('highly', 'recommend'), 0.00028736517556749754)\n",
      "(('really', 'like'), 0.0002731276131627599)\n",
      "(('fit', 'perfectly'), 0.00024142679062096127)\n",
      "(('fit', 'well'), 0.00023720001428205478)\n",
      "(('look', 'like'), 0.00022463091622162233)\n",
      "(('looks', 'great'), 0.00022034852440457235)\n",
      "(('look', 'great'), 0.00020477619052439055)\n",
      "(('another', 'pair'), 0.00020388634287409445)\n",
      "(('year', 'old'), 0.00019165093768252304)\n",
      "(('looks', 'like'), 0.00018842523995019967)\n",
      "(('feel', 'like'), 0.00018397600169871916)\n",
      "(('great', 'price'), 0.00018236315283255748)\n",
      "(('fit', 'great'), 0.00017435452397989256)\n",
      "(('even', 'though'), 0.00017073951790056463)\n",
      "(('usually', 'wear'), 0.00016645712608351465)\n",
      "(('light', 'weight'), 0.00015928272940300234)\n",
      "(('normally', 'wear'), 0.00015266448750392506)\n",
      "(('fits', 'well'), 0.00015166340889734194)\n",
      "(('would', 'buy'), 0.00015166340889734194)\n",
      "(('one', 'size'), 0.0001513297160284809)\n",
      "(('long', 'time'), 0.00014982809811860625)\n",
      "(('every', 'day'), 0.00014148577639708028)\n",
      "(('look', 'good'), 0.00013942800370577053)\n",
      "(('size', 'larger'), 0.00013881623344619198)\n",
      "(('arch', 'support'), 0.00013876061796804846)\n",
      "(('little', 'bit'), 0.0001321423760689712)\n",
      "(('first', 'time'), 0.00013158622128753614)\n",
      "(('fits', 'perfectly'), 0.00013158622128753614)\n",
      "(('really', 'nice'), 0.00013075198911538353)\n",
      "(('half', 'size'), 0.00012730382947048614)\n",
      "(('much', 'better'), 0.0001252460567791764)\n",
      "(('great', 'quality'), 0.00012452305556331082)\n",
      "(('looks', 'good'), 0.00012202035904685304)\n",
      "(('high', 'quality'), 0.00012007381731183032)\n",
      "(('perfect', 'fit'), 0.00011968450896482577)\n",
      "(('different', 'colors'), 0.00011796042914237707)\n",
      "(('fits', 'great'), 0.00011618073384178487)\n",
      "(('long', 'enough'), 0.00011445665401933617)\n",
      "(('flip', 'flops'), 0.00011206518845916539)\n",
      "(('would', 'definitely'), 0.00011189834202473487)\n",
      "(('really', 'cute'), 0.00010439025247536151)\n",
      "(('definitely', 'recommend'), 0.00010361163578135242)\n",
      "(('second', 'pair'), 0.0001034447893469219)\n",
      "(('super', 'cute'), 0.00010155386309004268)\n",
      "(('good', 'price'), 0.00010016347613645502)\n",
      "(('fit', 'perfect'), 9.938485944244593e-05)\n",
      "(('size', 'smaller'), 9.810570344514528e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIGRAMS BY  MUTUAL INFORMATION SCORES WITH FREQUENCY 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder1 = BigramCollocationFinder.from_words(mywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder1.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = finder1.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('krav', 'maga'), 21.778010214117682)\n",
      "(('salvatore', 'exte'), 21.778010214117682)\n",
      "(('spatestruck', 'lenders'), 21.778010214117682)\n",
      "(('tessuto', 'vela'), 21.778010214117682)\n",
      "(('workflex', 'ear-flap'), 21.778010214117682)\n",
      "(('pepto', 'bismol'), 21.514975808283886)\n",
      "(('herman', 'munster'), 21.292583386947438)\n",
      "(('birko', 'flor'), 21.09993830900504)\n",
      "(('norman', 'reedus'), 21.09993830900504)\n",
      "(('hola', 'gente'), 21.07019096561099)\n",
      "(('saudi', 'arabia'), 21.07019096561099)\n",
      "(('charlotte', 'russe'), 20.778010214117682)\n",
      "(('giorgio', 'brutini'), 20.77801021411768)\n",
      "(('grady', 'harp'), 20.77801021411768)\n",
      "(('johanna', 't25'), 20.640506690367744)\n",
      "(('sherpani', 'soleil'), 20.6145114818348)\n",
      "(('juanita', 'wilson'), 20.514975808283886)\n",
      "(('laurel', 'burch'), 20.488503596922698)\n",
      "(('carolyn', 'pollack'), 20.421866403892405)\n",
      "(('fecha', 'indicada'), 20.418114269031296)\n",
      "(('caslynn', 'lizzie'), 20.41544013473297)\n",
      "(('vince', 'camuto'), 20.345050806841574)\n",
      "(('buenas', 'tardes'), 20.292583386947438)\n",
      "(('gel-noosa', 'tri-7'), 20.292583386947438)\n",
      "(('muk', 'luks'), 20.27396770878009)\n",
      "(('liz', 'claiborne'), 20.225469191088898)\n",
      "(('puerto', 'rico'), 20.193047713396524)\n",
      "(('ventair', '504'), 20.193047713396524)\n",
      "(('audrey', 'hepburn'), 20.158490491360155)\n",
      "(('strawberry', 'shortcake'), 20.099938309005044)\n",
      "(('aurora', 'borealis'), 20.09993830900504)\n",
      "(('hanky', 'panky'), 20.09993830900504)\n",
      "(('bon', 'bebe'), 20.077570495976587)\n",
      "(('muay', 'thai'), 19.93001330756273)\n",
      "(('buzz', 'lightyear'), 19.930013307562728)\n",
      "(('darth', 'vader'), 19.914071763693713)\n",
      "(('nether', 'regions'), 19.903541096201536)\n",
      "(('scott', 'allan'), 19.884925418034193)\n",
      "(('hallux', 'limitus'), 19.877545887668596)\n",
      "(('tai', 'chi'), 19.877545887668596)\n",
      "(('alt', 'alt'), 19.86898387416517)\n",
      "(('betty', 'dravis'), 19.85201079556146)\n",
      "(('gloria', 'vanderbilt'), 19.852010795561455)\n",
      "(('pom', 'poms'), 19.852010795561455)\n",
      "(('ros', 'hommerson'), 19.778010214117685)\n",
      "(('haute', 'couture'), 19.737368229620333)\n",
      "(('viet', 'nam'), 19.695548053925705)\n",
      "(('itty', 'bitty'), 19.51497580828389)\n",
      "(('koh', 'koh'), 19.514975808283886)\n",
      "(('sora', 'b18'), 19.514975808283886)\n"
     ]
    }
   ],
   "source": [
    "for bigramscore in score[:50]:\n",
    "        print (bigramscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
